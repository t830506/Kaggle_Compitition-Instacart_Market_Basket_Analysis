{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run preprocessing.py\n",
    "print (\"shape of usersXprod :\", usersXprod.shape)\n",
    "print (usersXprod.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 對於購買力很差的顧客做篩選  \n",
    "針對一些超愛reordered跟超愛亂買的消費者做刪除 (high, normal, low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (train, test): (131209, 75000)\n",
    "\n",
    "t_afew = 20\n",
    "t_low = 0.1\n",
    "\n",
    "afewXlow = usersXprod[(usersXprod.eval_set == \"train\")&(usersXprod.user_total_product <= t_afew)&(usersXprod.user_reorder_ratio < t_low)]\n",
    "afew = usersXprod[(usersXprod.eval_set == \"train\")&(usersXprod.user_total_product <= t_afew)]\n",
    "low = usersXprod[(usersXprod.eval_set == \"train\")&(usersXprod.user_reorder_ratio < t_low)]\n",
    "\n",
    "print (\"user of afewXlow :\", len(set(afewXlow.user_id)))\n",
    "print (\"user of afew :\", len(set(afew.user_id)))\n",
    "print (\"user of low :\", len(set(low.user_id)))\n",
    "print (\"usersXprod of afewXlow :\", afewXlow.shape[0]/usersXprod[(usersXprod.eval_set == \"train\")].shape[0])\n",
    "print (\"usersXprod of afew :\", afew.shape[0]/usersXprod[(usersXprod.eval_set == \"train\")].shape[0])\n",
    "print (\"usersXprod of low :\", low.shape[0]/usersXprod[(usersXprod.eval_set == \"train\")].shape[0])\n",
    "\n",
    "del afewXlow\n",
    "del afew\n",
    "del low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "con_train = (usersXprod.eval_set == \"train\")&(usersXprod.user_reorder_ratio >= t_low)\n",
    "con_test = (usersXprod.eval_set == \"test\")\n",
    "\n",
    "train = usersXprod[con_train]\n",
    "train = train.drop([\"eval_set\", \"user_id\", \"product_id\", \"order_id\"], axis=1)\n",
    "\n",
    "test0 = usersXprod[con_test]\n",
    "test = test0.drop([\"eval_set\", \"user_id\", \"product_id\", \"order_id\", \"reordered\"], axis=1)\n",
    "\n",
    "#del usersXprod\n",
    "print(\"size of training set :\", train.shape[0])\n",
    "print(\"size of testing set :\", test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = train.drop([\"reordered\"], axis = 1)\n",
    "y = train[[\"reordered\"]]\n",
    "\n",
    "class_weight_0 = (y.shape[0] - np.sum(y.reordered)) / y.shape[0]\n",
    "class_weight_1 = np.sum(y.reordered) / y.shape[0]\n",
    "\n",
    "print(\"Size of features of dataset :\", X.shape[1])\n",
    "print(\"Class weight of 0 :\", class_weight_0)\n",
    "print(\"Class weight of 1 :\", class_weight_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, VotingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler(with_mean = True, with_std = True)\n",
    "X_std = sc.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_std = sc.fit_transform(test)\n",
    "threshold = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def validation(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    print(str(model), \"cross_val down\")\n",
    "    y_pred = model.predict(X_val).reshape(y_val.shape[0], 1)\n",
    "    print('Misclassified samples: %d' % (y_val != y_pred).sum())\n",
    "    print('Accuracy : %.2f' % ((y_val == y_pred).sum() / y_val.shape[0]))\n",
    "    print('Accuracy (sklearn): %.2f' % accuracy_score(y_val, y_pred))\n",
    "    print(\"=== Confusion Matrix ===\")\n",
    "    print(confusion_matrix(y_val, y_pred, labels = [0,1], sample_weight = None))\n",
    "    print(\"=== F1-score ===\")\n",
    "    print(f1_score(y_val, y_pred, labels=[0,1]))\n",
    "\n",
    "# 整理過的testing dataset 去預測\n",
    "# 拿出以前的商品顧客組合去預測是否reordered    \n",
    "# 建立一個門檻值去篩選是否購買???\n",
    "# 選出指定order_id 購買的商品並匯出\n",
    "def cross_val_and_testing(df, df_test, model, threshold):\n",
    "    model.fit(X, y)\n",
    "    print (cross_val_score(model, np.array(X), np.array(y).reshape(y.shape[0], ), cv=5))\n",
    "    print (\"Fitting Over\")\n",
    "    pred = pd.DataFrame(model.predict_proba(df_test), columns = [\"prob_0\", \"prob_1\"])\n",
    "    df[\"prediction\"] = pred[\"prob_1\"]\n",
    "    df = df[[\"order_id\", \"product_id\", \"prediction\"]]\n",
    "\n",
    "    con = (df.prediction > threshold)\n",
    "    test0_0 = df[~con]\n",
    "    test0_1 = df[con]\n",
    "    print(\"Percent of test0 is 0 :\", test0_0.shape[0]/df.shape[0])\n",
    "    print(\"Percent of test0 is 1 :\", test0_1.shape[0]/df.shape[0])\n",
    "\n",
    "    f = lambda x: np.array_split(list(set(x)), 1)[0]\n",
    "    order_prod = test0_1.groupby('order_id')[\"product_id\"].apply(f).reset_index()\n",
    "    order_id = df.groupby(\"order_id\")[\"product_id\"].apply(f).reset_index()\n",
    "    submit = pd.merge(order_id[[\"order_id\"]], order_prod, how='left', on=['order_id'])\n",
    "    return submit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lg = LogisticRegression(penalty = 'l2',\n",
    "                        dual = False,\n",
    "                        tol = 0.0001,\n",
    "                        C = 0.1,\n",
    "                        fit_intercept = True,\n",
    "                        intercept_scaling = 1,\n",
    "                        class_weight = {1: class_weight_1, 0: class_weight_0},\n",
    "                        random_state = 100,\n",
    "                        solver = 'liblinear',\n",
    "                        max_iter = 10,\n",
    "                        multi_class = 'ovr',\n",
    "                        verbose = 0,\n",
    "                        warm_start = False,\n",
    "                        n_jobs = 1)\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion = 'entropy', \n",
    "                              max_depth = None, \n",
    "                              random_state = 0,\n",
    "                              class_weight = {1: class_weight_1, 0: class_weight_0})\n",
    "\n",
    "tree_3 = DecisionTreeClassifier(criterion = 'entropy', \n",
    "                                max_depth = 3, \n",
    "                                random_state = 0,\n",
    "                                class_weight = {1: class_weight_1, 0: class_weight_0})\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators = 10,\n",
    "                             criterion = 'entropy',\n",
    "                             max_depth = None,\n",
    "                             min_samples_split = 2,\n",
    "                             min_samples_leaf = 1,\n",
    "                             min_weight_fraction_leaf = 0.0,\n",
    "                             max_features = 'auto',\n",
    "                             max_leaf_nodes = None,\n",
    "                             min_impurity_split = 1e-07,\n",
    "                             bootstrap = True,\n",
    "                             oob_score = False,\n",
    "                             n_jobs = 1,\n",
    "                             random_state = 100,\n",
    "                             verbose = 0,\n",
    "                             warm_start = False,\n",
    "                             class_weight = {1: class_weight_1, 0: class_weight_0})\n",
    "\n",
    "bc = BaggingClassifier(base_estimator = tree,  \n",
    "                       n_estimators = 10,  \n",
    "                       max_samples = 1.0,  \n",
    "                       max_features = 1.0,  \n",
    "                       bootstrap = True,  \n",
    "                       bootstrap_features = False,  \n",
    "                       oob_score = False,  \n",
    "                       warm_start = False,  \n",
    "                       n_jobs = 1,  \n",
    "                       random_state = None,  \n",
    "                       verbose = 0)\n",
    "\n",
    "abc = AdaBoostClassifier(base_estimator = tree_3,\n",
    "                         n_estimators = 50,\n",
    "                         learning_rate = 1.0,\n",
    "                         algorithm = 'SAMME.R',\n",
    "                         random_state = 100)\n",
    "\n",
    "vc = VotingClassifier(estimators = [(\"rfc\", rfc), (\"bc\", bc), (\"abc\", abc)],\n",
    "                      voting = \"soft\",\n",
    "                      weights = [2, 2, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validation(tree)\n",
    "submit = cross_val_and_testing(df=test0, df_test=test, model=tree, threshold=threshold)\n",
    "submit.to_csv(\"submit_tree.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "imp = pd.DataFrame(data = tree.feature_importances_,\n",
    "                   index = X_train.columns,\n",
    "                   columns = [\"important\"])\n",
    "imp.plot.bar(alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation(rfc)\n",
    "submit = cross_val_and_testing(df=test0, df_test=test, model=rfc, threshold=threshold)\n",
    "submit.to_csv(\"submit_rfc.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation(bc)\n",
    "submit = cross_val_and_testing(df=test0, df_test=test, model=bc, threshold=threshold)\n",
    "submit.to_csv(\"submit_bc.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation(abc)\n",
    "submit = cross_val_and_testing(df=test0, df_test=test, model=abc, threshold=threshold)\n",
    "submit.to_csv(\"submit_abc.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation(vc)\n",
    "submit = cross_val_and_testing(df=test0, df_test=test, model=vc, threshold=threshold)\n",
    "submit.to_csv(\"submit_vc.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bc1 = BaggingClassifier(base_estimator = bc,  \n",
    "                        n_estimators = 10,  \n",
    "                        max_samples = 1.0,  \n",
    "                        max_features = 1.0,  \n",
    "                        bootstrap = True,  \n",
    "                        bootstrap_features = False,  \n",
    "                        oob_score = False,  \n",
    "                        warm_start = False,  \n",
    "                        n_jobs = 1,  \n",
    "                        random_state = None,  \n",
    "                        verbose = 0)\n",
    "\n",
    "validation(bc1)\n",
    "submit = cross_val_and_testing(df=test0, df_test=test, model=bc1, threshold=threshold)\n",
    "submit.to_csv(\"submit_bc1.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bc2 = BaggingClassifier(base_estimator = bc1,  \n",
    "                        n_estimators = 10,  \n",
    "                        max_samples = 1.0,  \n",
    "                        max_features = 1.0,  \n",
    "                        bootstrap = True,  \n",
    "                        bootstrap_features = False,  \n",
    "                        oob_score = False,  \n",
    "                        warm_start = False,  \n",
    "                        n_jobs = 1,  \n",
    "                        random_state = None,  \n",
    "                        verbose = 0)\n",
    "\n",
    "validation(bc2)\n",
    "submit = cross_val_and_testing(df=test0, df_test=test, model=bc2, threshold=threshold)\n",
    "submit.to_csv(\"submit_bc2.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 描述現象\n",
    "2. 歸類users\n",
    "3. 分user建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

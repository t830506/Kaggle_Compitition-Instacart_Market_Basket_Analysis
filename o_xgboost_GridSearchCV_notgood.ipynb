{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import data\n",
      "merge orders and order_products__prior\n",
      "size of prd features : 5\n",
      "size of users features : 13\n",
      "nb of usersXproducts features : 13\n",
      "merge prod, user and usersXprod feature on usersXprod\n",
      "order row 2000000\n",
      "order row 4000000\n",
      "order row 6000000\n",
      "order row 8000000\n",
      "order row 10000000\n",
      "order row 12000000\n",
      "shape of usersXprod : (13307953, 32)\n"
     ]
    }
   ],
   "source": [
    "# 變數前處理\n",
    "\n",
    "%run preprocessing.py\n",
    "print (\"shape of usersXprod :\", usersXprod.shape)\n",
    "\n",
    "p = pd.read_csv(\"products.csv\")\n",
    "p = p.drop([\"product_name\"], axis=1)\n",
    "usersXprod = pd.merge(usersXprod, p, how='left', on=['product_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class tick_tock:\n",
    "    def __init__(self, process_name, verbose=1):\n",
    "        self.process_name = process_name\n",
    "        self.verbose = verbose\n",
    "    def __enter__(self):\n",
    "        if self.verbose:\n",
    "            print(self.process_name + \" begin ......\")\n",
    "            self.begin_time = time.time()\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        if self.verbose:\n",
    "            end_time = time.time()\n",
    "            print(self.process_name + \" end ......\")\n",
    "            print('time lapsing {0} s \\n'.format(end_time - self.begin_time))\n",
    "\n",
    "# convert to form of submit\n",
    "def ka_add_groupby_features_n_vs_1(df, group_columns_list, target_columns_list, methods_list, keep_only_stats=True, verbose=1):\n",
    "    '''Create statistical columns, group by [N columns] and compute stats on [1 column]\n",
    "\n",
    "       Parameters\n",
    "       ----------\n",
    "       df: pandas dataframe\n",
    "          Features matrix\n",
    "       group_columns_list: list_like\n",
    "          List of columns you want to group with, could be multiple columns\n",
    "       target_columns_list: list_like\n",
    "          column you want to compute stats, need to be a list with only one element\n",
    "       methods_list: list_like\n",
    "          methods that you want to use, all methods that supported by groupby in Pandas\n",
    "\n",
    "       Return\n",
    "       ------\n",
    "       new pandas dataframe with original columns and new added columns\n",
    "\n",
    "       Example\n",
    "       -------\n",
    "       ka_add_stats_features_n_vs_1(train, group_columns_list=['x0'], target_columns_list=['x10'])\n",
    "    '''\n",
    "    with tick_tock(\"add stats features\", verbose):\n",
    "        dicts = {\"group_columns_list\": group_columns_list , \"target_columns_list\": target_columns_list, \"methods_list\" :methods_list}\n",
    "\n",
    "        for k, v in dicts.items():\n",
    "            try:\n",
    "                if type(v) == list:\n",
    "                    pass\n",
    "                else:\n",
    "                    raise TypeError(k + \"should be a list\")\n",
    "            except TypeError as e:\n",
    "                print(e)\n",
    "                raise\n",
    "\n",
    "        grouped_name = ''.join(group_columns_list)\n",
    "        target_name = ''.join(target_columns_list)\n",
    "        combine_name = [[grouped_name] + [method_name] + [target_name] for method_name in methods_list]\n",
    "\n",
    "        df_new = df.copy()\n",
    "        grouped = df_new.groupby(group_columns_list)\n",
    "\n",
    "        the_stats = grouped[target_name].agg(methods_list).reset_index()\n",
    "        the_stats.columns = [grouped_name] + \\\n",
    "                            ['_%s_%s_by_%s' % (grouped_name, method_name, target_name) \\\n",
    "                             for (grouped_name, method_name, target_name) in combine_name]\n",
    "        if keep_only_stats:\n",
    "            return the_stats\n",
    "        else:\n",
    "            df_new = pd.merge(left=df_new, right=the_stats, on=group_columns_list, how='left')\n",
    "        return df_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Shawn/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "\n",
    "train = usersXprod.loc[usersXprod.eval_set == \"train\",:]\n",
    "train.drop(['eval_set', 'user_id', 'product_id', 'order_id'], axis=1, inplace=True)\n",
    "\n",
    "X_test = usersXprod.loc[usersXprod.eval_set == \"test\",:]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train.drop('reordered', axis=1),\n",
    "                                                  train.reordered,\n",
    "                                                  test_size = 0.99,\n",
    "                                                  random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV] colsample_bytree=0.95, gamma=0.7, learning_rate=0.05, max_depth=6, min_child_weight=10, n_estimators=300, objective=reg:logistic, subsample=0.76 \n",
      "[CV]  colsample_bytree=0.95, gamma=0.7, learning_rate=0.05, max_depth=6, min_child_weight=10, n_estimators=300, objective=reg:logistic, subsample=0.76, score=0.822501, total=  29.1s\n",
      "[CV] colsample_bytree=0.95, gamma=0.7, learning_rate=0.05, max_depth=6, min_child_weight=10, n_estimators=300, objective=reg:logistic, subsample=0.76 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   29.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.95, gamma=0.7, learning_rate=0.05, max_depth=6, min_child_weight=10, n_estimators=300, objective=reg:logistic, subsample=0.76, score=0.825677, total=  20.4s\n",
      "[CV] colsample_bytree=0.95, gamma=0.7, learning_rate=0.05, max_depth=6, min_child_weight=10, n_estimators=300, objective=reg:logistic, subsample=0.76 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   50.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.95, gamma=0.7, learning_rate=0.05, max_depth=6, min_child_weight=10, n_estimators=300, objective=reg:logistic, subsample=0.76, score=0.828048, total=  20.5s\n",
      "[CV] colsample_bytree=0.95, gamma=0.7, learning_rate=0.05, max_depth=6, min_child_weight=10, n_estimators=1000, objective=reg:logistic, subsample=0.76 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.95, gamma=0.7, learning_rate=0.05, max_depth=6, min_child_weight=10, n_estimators=1000, objective=reg:logistic, subsample=0.76, score=0.810908, total= 1.4min\n",
      "[CV] colsample_bytree=0.95, gamma=0.7, learning_rate=0.05, max_depth=6, min_child_weight=10, n_estimators=1000, objective=reg:logistic, subsample=0.76 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  2.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.95, gamma=0.7, learning_rate=0.05, max_depth=6, min_child_weight=10, n_estimators=1000, objective=reg:logistic, subsample=0.76, score=0.813783, total= 1.4min\n",
      "[CV] colsample_bytree=0.95, gamma=0.7, learning_rate=0.05, max_depth=6, min_child_weight=10, n_estimators=1000, objective=reg:logistic, subsample=0.76 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  4.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.95, gamma=0.7, learning_rate=0.05, max_depth=6, min_child_weight=10, n_estimators=1000, objective=reg:logistic, subsample=0.76, score=0.816393, total= 1.4min\n",
      "[CV] colsample_bytree=0.95, gamma=0.7, learning_rate=0.05, max_depth=8, min_child_weight=10, n_estimators=300, objective=reg:logistic, subsample=0.76 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  5.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.95, gamma=0.7, learning_rate=0.05, max_depth=8, min_child_weight=10, n_estimators=300, objective=reg:logistic, subsample=0.76, score=0.819059, total=  35.6s\n",
      "[CV] colsample_bytree=0.95, gamma=0.7, learning_rate=0.05, max_depth=8, min_child_weight=10, n_estimators=300, objective=reg:logistic, subsample=0.76 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  6.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.95, gamma=0.7, learning_rate=0.05, max_depth=8, min_child_weight=10, n_estimators=300, objective=reg:logistic, subsample=0.76, score=0.822444, total=  36.5s\n",
      "[CV] colsample_bytree=0.95, gamma=0.7, learning_rate=0.05, max_depth=8, min_child_weight=10, n_estimators=300, objective=reg:logistic, subsample=0.76 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  6.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.95, gamma=0.7, learning_rate=0.05, max_depth=8, min_child_weight=10, n_estimators=300, objective=reg:logistic, subsample=0.76, score=0.824074, total=  35.9s\n",
      "[CV] colsample_bytree=0.95, gamma=0.7, learning_rate=0.05, max_depth=8, min_child_weight=10, n_estimators=1000, objective=reg:logistic, subsample=0.76 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  7.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.95, gamma=0.7, learning_rate=0.05, max_depth=8, min_child_weight=10, n_estimators=1000, objective=reg:logistic, subsample=0.76, score=0.802900, total= 1.9min\n",
      "[CV] colsample_bytree=0.95, gamma=0.7, learning_rate=0.05, max_depth=8, min_child_weight=10, n_estimators=1000, objective=reg:logistic, subsample=0.76 \n",
      "[CV]  colsample_bytree=0.95, gamma=0.7, learning_rate=0.05, max_depth=8, min_child_weight=10, n_estimators=1000, objective=reg:logistic, subsample=0.76, score=0.807079, total= 2.0min\n",
      "[CV] colsample_bytree=0.95, gamma=0.7, learning_rate=0.05, max_depth=8, min_child_weight=10, n_estimators=1000, objective=reg:logistic, subsample=0.76 \n",
      "[CV]  colsample_bytree=0.95, gamma=0.7, learning_rate=0.05, max_depth=8, min_child_weight=10, n_estimators=1000, objective=reg:logistic, subsample=0.76, score=0.809041, total= 1.9min\n",
      "[CV] colsample_bytree=0.95, gamma=0.7, learning_rate=0.1, max_depth=6, min_child_weight=10, n_estimators=300, objective=reg:logistic, subsample=0.76 \n",
      "[CV]  colsample_bytree=0.95, gamma=0.7, learning_rate=0.1, max_depth=6, min_child_weight=10, n_estimators=300, objective=reg:logistic, subsample=0.76, score=0.816436, total=  26.4s\n",
      "[CV] colsample_bytree=0.95, gamma=0.7, learning_rate=0.1, max_depth=6, min_child_weight=10, n_estimators=300, objective=reg:logistic, subsample=0.76 \n",
      "[CV]  colsample_bytree=0.95, gamma=0.7, learning_rate=0.1, max_depth=6, min_child_weight=10, n_estimators=300, objective=reg:logistic, subsample=0.76, score=0.818131, total=  26.7s\n",
      "[CV] colsample_bytree=0.95, gamma=0.7, learning_rate=0.1, max_depth=6, min_child_weight=10, n_estimators=300, objective=reg:logistic, subsample=0.76 \n",
      "[CV]  colsample_bytree=0.95, gamma=0.7, learning_rate=0.1, max_depth=6, min_child_weight=10, n_estimators=300, objective=reg:logistic, subsample=0.76, score=0.820747, total=  26.5s\n",
      "[CV] colsample_bytree=0.95, gamma=0.7, learning_rate=0.1, max_depth=6, min_child_weight=10, n_estimators=1000, objective=reg:logistic, subsample=0.76 \n",
      "[CV]  colsample_bytree=0.95, gamma=0.7, learning_rate=0.1, max_depth=6, min_child_weight=10, n_estimators=1000, objective=reg:logistic, subsample=0.76, score=0.797237, total= 1.4min\n",
      "[CV] colsample_bytree=0.95, gamma=0.7, learning_rate=0.1, max_depth=6, min_child_weight=10, n_estimators=1000, objective=reg:logistic, subsample=0.76 \n",
      "[CV]  colsample_bytree=0.95, gamma=0.7, learning_rate=0.1, max_depth=6, min_child_weight=10, n_estimators=1000, objective=reg:logistic, subsample=0.76, score=0.798364, total= 1.3min\n",
      "[CV] colsample_bytree=0.95, gamma=0.7, learning_rate=0.1, max_depth=6, min_child_weight=10, n_estimators=1000, objective=reg:logistic, subsample=0.76 \n",
      "[CV]  colsample_bytree=0.95, gamma=0.7, learning_rate=0.1, max_depth=6, min_child_weight=10, n_estimators=1000, objective=reg:logistic, subsample=0.76, score=0.802514, total= 1.3min\n",
      "[CV] colsample_bytree=0.95, gamma=0.7, learning_rate=0.1, max_depth=8, min_child_weight=10, n_estimators=300, objective=reg:logistic, subsample=0.76 \n",
      "[CV]  colsample_bytree=0.95, gamma=0.7, learning_rate=0.1, max_depth=8, min_child_weight=10, n_estimators=300, objective=reg:logistic, subsample=0.76, score=0.805774, total=  39.4s\n",
      "[CV] colsample_bytree=0.95, gamma=0.7, learning_rate=0.1, max_depth=8, min_child_weight=10, n_estimators=300, objective=reg:logistic, subsample=0.76 \n",
      "[CV]  colsample_bytree=0.95, gamma=0.7, learning_rate=0.1, max_depth=8, min_child_weight=10, n_estimators=300, objective=reg:logistic, subsample=0.76, score=0.810648, total=  35.5s\n",
      "[CV] colsample_bytree=0.95, gamma=0.7, learning_rate=0.1, max_depth=8, min_child_weight=10, n_estimators=300, objective=reg:logistic, subsample=0.76 \n",
      "[CV]  colsample_bytree=0.95, gamma=0.7, learning_rate=0.1, max_depth=8, min_child_weight=10, n_estimators=300, objective=reg:logistic, subsample=0.76, score=0.812988, total=  38.0s\n",
      "[CV] colsample_bytree=0.95, gamma=0.7, learning_rate=0.1, max_depth=8, min_child_weight=10, n_estimators=1000, objective=reg:logistic, subsample=0.76 \n",
      "[CV]  colsample_bytree=0.95, gamma=0.7, learning_rate=0.1, max_depth=8, min_child_weight=10, n_estimators=1000, objective=reg:logistic, subsample=0.76, score=0.788891, total= 2.1min\n",
      "[CV] colsample_bytree=0.95, gamma=0.7, learning_rate=0.1, max_depth=8, min_child_weight=10, n_estimators=1000, objective=reg:logistic, subsample=0.76 \n",
      "[CV]  colsample_bytree=0.95, gamma=0.7, learning_rate=0.1, max_depth=8, min_child_weight=10, n_estimators=1000, objective=reg:logistic, subsample=0.76, score=0.792706, total= 2.1min\n",
      "[CV] colsample_bytree=0.95, gamma=0.7, learning_rate=0.1, max_depth=8, min_child_weight=10, n_estimators=1000, objective=reg:logistic, subsample=0.76 \n",
      "[CV]  colsample_bytree=0.95, gamma=0.7, learning_rate=0.1, max_depth=8, min_child_weight=10, n_estimators=1000, objective=reg:logistic, subsample=0.76, score=0.796220, total= 1.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed: 27.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.95,\n",
      "       gamma=0.7, learning_rate=0.05, max_delta_step=0, max_depth=6,\n",
      "       min_child_weight=10, missing=None, n_estimators=300, nthread=-1,\n",
      "       objective='reg:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.76)\n"
     ]
    }
   ],
   "source": [
    "# Choose classifier\n",
    "clf = xgboost.XGBClassifier(verbose = 100)\n",
    "\n",
    "# Parameters to try\n",
    "xgb_params = {\n",
    "    \"objective\"        : [\"reg:logistic\"],\n",
    "    'learning_rate'    : [0.05, 0.1],\n",
    "    \"max_depth\"        : [6, 8],\n",
    "    \"min_child_weight\" : [10],\n",
    "    \"gamma\"            : [0.70],\n",
    "    \"subsample\"        : [0.76],\n",
    "    \"n_estimators\"     : [300, 1000], #number of trees, change it to 1000 for better results          \n",
    "    \"colsample_bytree\" : [0.95]\n",
    "}\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(clf, xgb_params, scoring = 'roc_auc', verbose = 100)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "clf = grid_obj.best_estimator_\n",
    "print(clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.909264158219\n"
     ]
    }
   ],
   "source": [
    "# Fit the best algorithm to the data. \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_val)\n",
    "print(accuracy_score(y_val, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.95,\n",
       "       gamma=0.7, learning_rate=0.05, max_delta_step=0, max_depth=6,\n",
       "       min_child_weight=10, missing=None, n_estimators=300, nthread=-1,\n",
       "       objective='reg:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=0.76)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier as bc\n",
    "bc = bc(base_estimator     = clf,\n",
    "        n_estimators       = 10,\n",
    "        max_samples        = 1.0,\n",
    "        max_features       = 1.0,\n",
    "        bootstrap          = True,\n",
    "        bootstrap_features = True,\n",
    "        oob_score          = False,\n",
    "        warm_start         = False,\n",
    "        n_jobs             = 1,\n",
    "        random_state       = 2,\n",
    "        verbose            = 10)\n",
    "\n",
    "clf.fit(train.drop('reordered', axis=1), train.reordered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add stats features begin ......\n",
      "add stats features end ......\n",
      "time lapsing 2.597749948501587 s \n",
      "\n",
      "75000 43492\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "# convert to the form of submit\n",
    "\n",
    "d_test = X_test.drop(['eval_set', 'user_id', 'order_id', 'reordered', 'product_id'], axis=1)\n",
    "X_test.loc[:, 'reordered'] = (clf.predict(d_test) > 0.21).astype(int)\n",
    "X_test.loc[:, 'product_id'] = X_test.product_id.astype(str)\n",
    "\n",
    "submit = ka_add_groupby_features_n_vs_1(X_test[X_test.reordered == 1], \n",
    "                                        group_columns_list = ['order_id'],\n",
    "                                        target_columns_list = ['product_id'],\n",
    "                                        methods_list = [lambda x: ' '.join(set(x))],\n",
    "                                        keep_only_stats = True)\n",
    "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
    "print (len(sample_submission), len(submit))\n",
    "\n",
    "submit.columns = sample_submission.columns.tolist()\n",
    "submit_final = sample_submission[['order_id']].merge(submit, how='left').fillna('None')\n",
    "submit_final.to_csv(\"submit_xgboost_GridSearchCV.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
